---
permalink: /
title: "Personal page of Changsong Wen"
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Welcome! I am Guoli Jia (贾国力 in Chinese). I am a first-year PHD student at the [Electrical Engineering Department](https://www.ee.tsinghua.edu.cn), [Tsinghua University](https://www.tsinghua.edu.cn), advised by Prof. [Bowen Zhou](http://web.ee.tsinghua.edu.cn/zhoubowen/zh_CN/index.htm). Prior to my master's career, I achieved my master's degree supervised by Prof [Jufeng Yang](https://cv.nankai.edu.cn) , and received my bachelor's degree at the School of [Software Engineering](http://www.sei.ecnu.edu.cn/), [East China Normal University](https://www.ecnu.edu.cn/) in 2021.

My research interest is multi-modal generation. I am always looking for related collaborations,  feel free to drop me an <a href="mailto:exped1230@gmail.com" target="_blank">email</a> if you are interested!


# 📖 Educations
- *2024.09 - now*, PHD student of Nankai University. 
- *2021.09 - 2024.06*, Master student of Nankai University. 
- *2017.09 - 2021.07*, Undergraduate students of East China Normal University.

# 🔥 News
* **[2024.10.28]** &nbsp;🎉🎉 I organize an ACM MM tutorial titled “Label Efficient Emotion and Sentiment Analysis” as one of the main members, the related materials is available [here](https://github.com/exped1230/Label-Efficient-Emotion-and-Sentiment-Analysis).
* **[2024.06.17]** &nbsp;🎉🎉 I am selected as an [Outstanding Reviewer for CVPR 2024](https://cvpr.thecvf.com/Conferences/2024/ProgramCommittee#outstanding-reviewers).
* **[2024.02.02]** &nbsp;🎉🎉 1 paper is accepted to [TAFFC](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5165369).
* **[2023.11.02]** &nbsp;🎖🎖 I receive the first prize of the Nankai University Public Scholarship.
* **[2023.05.08]** &nbsp;🎖🎖 I receive the SK AI Innovation Scholarship from Korea.
* **[2023.02.28]** &nbsp;🎉🎉 1 paper is accepted to [CVPR 2023](https://cvpr.thecvf.com/Conferences/2023).
* **[2022.07.04]** &nbsp;🎉🎉 1 paper is accepted to [ECCV 2022](https://eccv2022.ecva.net/).
* **[2022.06.30]** &nbsp;🎉🎉 1 paper is accepted to [ACM MM 2022](https://2022.acmmm.org/).


# 📝 Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='../images/salience.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<img src="https://img.shields.io/badge/CVPR-2024-blue?style=flat-square"> Pancheng Zhao, Peng Xu, Pengda Qin, Dengping Fan, Zhicheng Zhang, <u>Guoli Jia</u>, Bowen Zhou, Jufeng Yang, &quot;**LAKE-RED: Camouflaged Images Generation by Latent Background Knowledge Retrieval-Augmented Diffusion**&quot;. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2024*. 

[[pdf](https://arxiv.org/pdf/2404.00292)][[code](https://github.com/PanchengZhao/LAKE-RED)]

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TAFFC</div><img src='../images/gait.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<img src="https://img.shields.io/badge/TAFFC-2024-red?style=flat-square"> Yingjie Zhai†, <u>Guoli Jia†</u>, Yukun Lai, Jing Zhang, Jufeng Yang, Dacheng Tao, &quot;**Looking into Gait for Perceiving Emotions via Bilateral Posture and Movement Graph Convolutional Networks**&quot;. In *IEEE Transactions on Affective Computing (TAFFC) 2024*. 

[[pdf](https://ieeexplore.ieee.org/abstract/document/10433680)] [[code](https://github.com/exped1230/BPM-GCN)] [[project](https://exped1230.github.io/BPM-GCN/GaitEmotion-BPM-GCN/index.html)]

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2023</div><img src='../images/Sarcasm.PNG' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<img src="https://img.shields.io/badge/CVPR-2023-blue?style=flat-square"> Changsong Wen†, <u>Guoli Jia</u>†, Jufeng Yang, &quot;**DIP: Dual Incongruity Perceiving Network for Sarcasm Detection**&quot;. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2023*.

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wen_DIP_Dual_Incongruity_Perceiving_Network_for_Sarcasm_Detection_CVPR_2023_paper.pdf)] [[code](https://github.com/downdric/MSD)]
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV 2022</div><img src='../images/S2-VER.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<img src="https://img.shields.io/badge/ECCV-2022-blue?style=flat-square"> <u>Guoli Jia</u>, Jufeng Yang, &quot;**S2-VER: Semi-supervised Visual Emotion Recognition**&quot;. In *European Conference on Computer Vision*.

[[pdf](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136970483.pdf)] [[code](https://github.com/exped1230/S2-VER)] [[poster](https://github.com/exped1230/S2-VER/blob/main/S2-VER_poster.pdf)]

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2022</div><img src='../images/EASE.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<img src="https://img.shields.io/badge/ACM MM-2022-blue?style=flat-square"> Lijuan Wang†, <u>Guoli Jia</u>†, Ning Jiang, Haiying Wu, Jufeng Yang, &quot;**EASE: Robust facial expression recognition via emotion Ambiguity-SEnsitive cooperative networks**&quot;. In *Proceedings of the 30th ACM International Conference on Multimedia*.

[[pdf](https://dl.acm.org/doi/abs/10.1145/3503161.3548005)]

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">SPM</div><img src='../images/spm.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<img src="https://img.shields.io/badge/SPM-2021-red?style=flat-square"> Sicheng Zhao, <u>Guoli Jia</u>, Jufeng Yang, Guiguang Ding, Kurt Keutzer, &quot;**Emotion Recognition From Multiple Modalities: Fundamentals and methodologies**&quot;. In *IEEE Signal Processing Magazine (SPM)*.

[[pdf](https://ieeexplore.ieee.org/abstract/document/9591550)]

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TPAMI</div><img src='../images/AICA.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<img src="https://img.shields.io/badge/TPAMI-2021-red?style=flat-square"> Sicheng Zhao, Xingxu Yao, Jufeng Yang, <u>Guoli Jia</u>, Guiguang Ding, Tat-Seng CHua, 
Björn W. Schuller, 
Kurt Keutzer, &quot;**Affective Image Content Analysis: Two Decades Review and New Perspectives**&quot;. In *IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)*.

[[pdf](https://ieeexplore.ieee.org/abstract/document/9472932/)] [[code](https://github.com/exped1230/AICA)] [[poster](https://github.com/exped1230/AICA/blob/main/poster.pdf)]

</div>
</div>
